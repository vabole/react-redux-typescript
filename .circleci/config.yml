version: 2.1
orbs:
  snyk: snyk/snyk@0.0.8
jobs:
  build:
    docker:
      - image: circleci/node:12.13.0-browsers
    working_directory: /home/circleci/app
    steps:
      - checkout

      - restore_cache:
          key: v1-dep-{{ checksum "yarn.lock" }}

      - run:
          name: Install deps
          command: yarn install --frozen-lockfile

      - save_cache:
          paths:
            - ./node_modules
            - ~/.cache
          key: v1-dep-{{ checksum "yarn.lock" }}

      - run:
          name: Run tests
          command: yarn test

      - run:
          name: Run lint
          command: yarn lint

      - run:
          name: Check size
          command: yarn size
      - snyk/scan:
          fail-on-issues: false
          monitor-on-build: false
          severity-threshold: high

  # Perf tests
  parallelism: 3
  simpleTests:    
    docker:
      - image: kanopi/ci:edge-lighthouse
    steps:
      - checkout
      - run:
          name: Run lighthouse tests
          # Load the url to test from the JSON file.
          command: |
            TEST_URL="$(node -p 'require("./.circleci/lighthouse.json").url')"
            lighthouse $TEST_URL \
              --port=9222 \
              --chrome-flags=\"--headless\" \
              --emulated-form-factor=mobile \
              --output-path=/opt/reports/anonymous-"$(echo -n $CIRCLE_SHELL_ENV | md5sum | awk '{print $1}')" \
              --output=json \
              --output=html
      # Save the reports just generated in a place where the _next job_ in the
      # workflow can snag them all and do analysis on them. 
      - persist_to_workspace:
          root: /opt
          paths:
            - reports

  # Analyze all the reports for URL1
  processResultsSimpleTests:
    docker:
      - image: kanopi/ci:edge-lighthouse
    steps:
      - checkout
      # Mount the workspace (which contains all our reports) into this
      # container. The reports are subsequently available at ./reports/
      - attach_workspace:
          at: "."
      # Store the html and json reports in S3 as long-term artifacts associated
      # with this job. Then, we can easily send links to the html reports in the
      # PR comment.
      - store_artifacts:
          path: reports
          destination: reports
      # Run the script to parse the scores.
      - run:
          shell: /bin/sh
          name: Analyze scores for the tests
          command: |
            /opt/ci-scripts/analyze_scores.js ./.circleci/lighthouse.json reports
  baseUrl:
    docker:
      - image: kanopi/ci:edge-lighthouse
    steps:
      - checkout
      - attach_workspace:
          at: "."
      - run:
          # This is the simplest way to store variables between jobs.
          name: Create file for storing lighthouse base url
          command: |
            echo 'https://developers.google.com' > lighthouse_base_url
      # Save the lighthouse file in the workspace to be used by other jobs.
      - persist_to_workspace:
          root: ./
          paths:
            - lighthouse_base_url

  # Perf tests
  relativeTests:
    # Number of parallel Lighthouse runs against this url. Why more than one?
    # Some perf metrics vary across runs based on backend flakiness, etc, and
    # this way we can extract a best score or median across runs.
    parallelism: 3
    docker:
      - image: kanopi/ci:edge-lighthouse
    steps:
      - checkout
      - attach_workspace:
          at: "."
      - run:
          name: Run lighthouse tests
          # Load the base_url and the url to test and put them together.
          command: |
            LIGHTHOUSE_BASE_URL="$(cat ./lighthouse_base_url)"
            TEST_URL="$(node -p 'require("./.circleci/lighthouse-relative.json").url')"
            COMPLETE_URL="$LIGHTHOUSE_BASE_URL$TEST_URL"
            lighthouse $COMPLETE_URL \
              --port=9222 \
              --chrome-flags=\"--headless\" \
              --emulated-form-factor=mobile \
              --output-path=/opt/reports/anonymous-"$(echo -n $CIRCLE_SHELL_ENV | md5sum | awk '{print $1}')" \
              --output=json \
              --output=html
      # Save the reports just generated in a place where the _next job_ in the
      # workflow can snag them all and do analysis on them.
      - persist_to_workspace:
          root: /opt
          paths:
            - reports

  # Analyze reports
  processResultsRelativeTests:
    docker:
      - image: kanopi/ci:edge-lighthouse
    steps:
      - checkout
      # Mount the workspace (which contains all our reports) into this
      # container. The reports are subsequently available at ./reports/
      - attach_workspace:
          at: "."
      # Store the html and json reports in S3 as long-term artifacts associated
      # with this job. Then, we can easily send links to the html reports in the
      # PR comment.
      - store_artifacts:
          path: reports
          destination: reports
      # Run the script to parse the scores.
      - run:
          shell: /bin/sh
          name: Analyze scores for the tests
          command: |
            export LIGHTHOUSE_BASE_URL="$(cat ./lighthouse_base_url)"
            /opt/ci-scripts/analyze_scores.js ./.circleci/lighthouse-relative.json reports
workflows:
  version: 2
  simpleLighthouseBenchmark:
    jobs:      
      - build      
      - simpleTests:
          requires:
                - build
      - processResultsSimpleTests:
          requires:
            - simpleTests
  